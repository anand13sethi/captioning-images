{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pycocotools.coco import COCO\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (8.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.applications import VGG16\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(train=True):\n",
    "\n",
    "    if train:\n",
    "        filename = 'Dataset/captions_train2017.json'\n",
    "    else:\n",
    "        filename = 'Dataset/captions_val2017.json'\n",
    "\n",
    "    path = filename\n",
    "    \n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data_raw = json.load(file)\n",
    "\n",
    "    images = data_raw['images']\n",
    "    annotations = data_raw['annotations']\n",
    "    \n",
    "    records = dict()\n",
    "\n",
    "    for image in images:\n",
    "        image_id = image['id']\n",
    "        filename = image['file_name']\n",
    "        \n",
    "        record = dict()\n",
    "        \n",
    "        record['filename'] = filename\n",
    "        \n",
    "        record['captions'] = list()\n",
    "        \n",
    "        records[image_id] = record\n",
    "        \n",
    "    for ann in annotations:\n",
    "        \n",
    "        image_id = ann['image_id']\n",
    "        caption = ann['caption']\n",
    "        \n",
    "        record = records[image_id]\n",
    "        \n",
    "        record['captions'].append(caption)\n",
    "        \n",
    "    records_list = [(key, record['filename'], record['captions'])\n",
    "                    for key, record in sorted(records.items())]\n",
    "    \n",
    "    ids, filenames, captions = zip(*records_list)\n",
    "\n",
    "    return ids, filenames, captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, filenames_train, captions_train = load(train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_start = 'ssss '\n",
    "mark_end = ' eeee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_captions(captions_listlist):\n",
    "    captions_marked = [[mark_start + caption + mark_end\n",
    "                        for caption in captions_list]\n",
    "                        for captions_list in captions_listlist]\n",
    "    \n",
    "    return captions_marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ssss Closeup of bins of food that include broccoli and bread. eeee',\n",
       " 'ssss A meal is presented in brightly colored plastic trays. eeee',\n",
       " 'ssss there are containers filled with different kinds of foods eeee',\n",
       " 'ssss Colorful dishes holding meat, vegetables, fruit, and bread. eeee',\n",
       " 'ssss A bunch of trays that have different food. eeee']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_train_marked = mark_captions(captions_train)\n",
    "captions_train_marked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Closeup of bins of food that include broccoli and bread.',\n",
       " 'A meal is presented in brightly colored plastic trays.',\n",
       " 'there are containers filled with different kinds of foods',\n",
       " 'Colorful dishes holding meat, vegetables, fruit, and bread.',\n",
       " 'A bunch of trays that have different food.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(captions_listlist):\n",
    "    captions_list = [caption\n",
    "                     for captions_list in captions_listlist\n",
    "                     for caption in captions_list]\n",
    "    \n",
    "    return captions_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "captions_train_flat = flatten(captions_train_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrap(Tokenizer):\n",
    "    \n",
    "    def __init__(self, texts, num_words=None):\n",
    "\n",
    "        Tokenizer.__init__(self, num_words=num_words)\n",
    "        \n",
    "        self.fit_on_texts(texts)\n",
    "        \n",
    "        self.index_to_word = dict(zip(self.word_index.values(), self.word_index.keys()))\n",
    "\n",
    "    def token_to_word(self, token):\n",
    "\n",
    "        word = \" \" if token == 0 else self.index_to_word[token]\n",
    "        return word \n",
    "\n",
    "    def tokens_to_string(self, tokens):\n",
    "        \n",
    "        words = [self.index_to_word[token]\n",
    "                 for token in tokens\n",
    "                 if token != 0]\n",
    "        \n",
    "        text = \" \".join(words)\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def captions_to_tokens(self, captions_listlist):\n",
    "        \n",
    "        tokens = [self.texts_to_sequences(captions_list)\n",
    "                  for captions_list in captions_listlist]\n",
    "        \n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TokenizerWrap(texts=captions_train_flat, num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start = tokenizer.word_index[mark_start.strip()]\n",
    "token_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_end = tokenizer.word_index[mark_end.strip()]\n",
    "token_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = tokenizer.captions_to_tokens(captions_train_marked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 841, 5, 2864, 5, 61, 26, 1984, 238, 9, 433, 3],\n",
       " [2, 1, 429, 10, 3310, 7, 1025, 390, 501, 1110, 3],\n",
       " [2, 63, 19, 993, 143, 8, 190, 958, 5, 743, 3],\n",
       " [2, 299, 725, 25, 343, 208, 264, 9, 433, 3],\n",
       " [2, 1, 170, 5, 1110, 26, 446, 190, 61, 3]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ssss Closeup of bins of food that include broccoli and bread. eeee',\n",
       " 'ssss A meal is presented in brightly colored plastic trays. eeee',\n",
       " 'ssss there are containers filled with different kinds of foods eeee',\n",
       " 'ssss Colorful dishes holding meat, vegetables, fruit, and bread. eeee',\n",
       " 'ssss A bunch of trays that have different food. eeee']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "captions_train_marked[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
